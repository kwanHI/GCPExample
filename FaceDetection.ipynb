{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection via Google Vision API\n",
    "\n",
    "#### Derived from\n",
    "  * https://cloud.google.com/vision/docs/detecting-faces\n",
    "  * https://github.com/GoogleCloudPlatform/python-docs-samples/tree/master/vision/cloud-client/detect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create a preemptible instance and install the required packages\n",
    "\n",
    "1.Create a preemptible instance: \n",
    "\n",
    " https://cloud.google.com/compute/docs/instances/create-start-preemptible-instance\n",
    "\n",
    "2.Install the following packages:\n",
    "   * sudo apt install python-pip\n",
    "   * pip install --upgrade google-api-python-client\n",
    "   * pip install --upgrade google-cloud-datastore\n",
    "   * pip install google-cloud-vision\n",
    "   * pip install pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 2: Create a JSON credentials file\n",
    "\n",
    "* In console.cloud.google.com, go to IAM & Admin\n",
    "* Select Service Accounts\n",
    "* Create a service account\n",
    "* Create a key and save the key as key.json in the root of your home directory in the VM\n",
    "* Transfer the key.json file to your VM (via cut-and-paste or scp)\n",
    "* In the VM, issue this command: export GOOGLE_APPLICATION_CREDENTIALS=~/key.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export GOOGLE_APPLICATION_CREDENTIALS=~/cloud15-lcn1055service.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3:  Download the Input image shown below to your VM \n",
    "\n",
    "  * gsutil cp gs://dsa-facebucket/wisdom_of_the_crowd.jpg .\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsutil cp gs://dsa-facebucket/wisdom_of_the_crowd.jpg ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4:  Please give these cells a read through... and as you do, move them to a file in your virtual machine, such as\n",
    "\n",
    "    FaceDetection.py\n",
    "\n",
    "Alternatively, see the Notebook python script extraction example at the bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision_v1 import types\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "\n",
    "\n",
    "def highlight_faces(image, faces, output_filename):\n",
    "    \"\"\"Draws a polygon around the faces, then saves to output_filename.\n",
    "\n",
    "    Args:\n",
    "      image: a file containing the image with the faces.\n",
    "      faces: a list of faces found in the file. This should be in the format\n",
    "          returned by the Vision API.\n",
    "      output_filename: the name of the image file to be created, where the\n",
    "          faces have polygons drawn around them.\n",
    "    \"\"\"\n",
    "    im = Image.open(image)\n",
    "    draw = ImageDraw.Draw(im)\n",
    "\n",
    "    for face in faces:\n",
    "        box = [(vertex.x, vertex.y)\n",
    "               for vertex in face.bounding_poly.vertices]\n",
    "        draw.line(box + [box[0]], width=5, fill='#00ff00')\n",
    "\n",
    "    im.save(output_filename)\n",
    " \n",
    "def look_for_faces(input_filename, output_filename, max_results):\n",
    "    with open(input_filename, 'rb') as image:\n",
    "        faces = detect_face(image, max_results)\n",
    "        print('Found {} face{}'.format(\n",
    "            len(faces), '' if len(faces) == 1 else 's'))\n",
    "\n",
    "        print('Writing to file {}'.format(output_filename))\n",
    "        # Reset the file pointer, so we can read the file again\n",
    "        image.seek(0)\n",
    "        highlight_faces(image, faces, output_filename)\n",
    "        \n",
    "        \n",
    "def detect_face(face_file, max_results=4):\n",
    "    \"\"\"Uses the Vision API to detect faces in the given file.\n",
    "\n",
    "    Args:\n",
    "        face_file: A file-like object containing an image with faces.\n",
    "\n",
    "    Returns:\n",
    "        An array of Face objects with information about the picture.\n",
    "    \"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    content = face_file.read()\n",
    "    image = types.Image(content=content)\n",
    "\n",
    "    return client.face_detection(image=image).face_annotations\n",
    "\n",
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "\n",
    "INPUT_IMAGE=\"faces.jpg\"\n",
    "OUTPUT_IMAGE=\"DETECTED_WISDOM.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision_v1 import types\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def detect_face(face_file, max_results=4):\n",
    "    \"\"\"Uses the Vision API to detect faces in the given file.\n",
    "\n",
    "    Args:\n",
    "        face_file: A file-like object containing an image with faces.\n",
    "\n",
    "    Returns:\n",
    "        An array of Face objects with information about the picture.\n",
    "    \"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    content = face_file.read()\n",
    "    image = types.Image(content=content)\n",
    "\n",
    "    return client.face_detection(image=image).face_annotations\n",
    "\n",
    "\n",
    "def highlight_faces(image, faces, output_filename):\n",
    "    \"\"\"Draws a polygon around the faces, then saves to output_filename.\n",
    "\n",
    "    Args:\n",
    "      image: a file containing the image with the faces.\n",
    "      faces: a list of faces found in the file. This should be in the format\n",
    "          returned by the Vision API.\n",
    "      output_filename: the name of the image file to be created, where the\n",
    "          faces have polygons drawn around them.\n",
    "    \"\"\"\n",
    "    im = Image.open(image)\n",
    "    draw = ImageDraw.Draw(im)\n",
    "\n",
    "    for face in faces:\n",
    "        box = [(vertex.x, vertex.y)\n",
    "               for vertex in face.bounding_poly.vertices]\n",
    "        draw.line(box + [box[0]], width=5, fill='#00ff00')\n",
    "\n",
    "    im.save(output_filename)\n",
    " \n",
    "\n",
    "def look_for_faces(input_filename, output_filename, max_results):\n",
    "    with open(input_filename, 'rb') as image:\n",
    "        faces = detect_face(image, max_results)\n",
    "        print('Found {} face{}'.format(\n",
    "            len(faces), '' if len(faces) == 1 else 's'))\n",
    "\n",
    "        print('Writing to file {}'.format(output_filename))\n",
    "        # Reset the file pointer, so we can read the file again\n",
    "        image.seek(0)\n",
    "        highlight_faces(image, faces, output_filename)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "INPUT_IMAGE=\"wisdom_of_the_crowd.jpg\"\n",
    "OUTPUT_IMAGE=\"DETECTED_WISDOM.jpg\"\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_face(face_file, max_results=4):\n",
    "    \"\"\"Uses the Vision API to detect faces in the given file.\n",
    "\n",
    "    Args:\n",
    "        face_file: A file-like object containing an image with faces.\n",
    "\n",
    "    Returns:\n",
    "        An array of Face objects with information about the picture.\n",
    "    \"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    content = face_file.read()\n",
    "    image = types.Image(content=content)\n",
    "\n",
    "    return client.face_detection(image=image).face_annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def highlight_faces(image, faces, output_filename):\n",
    "    \"\"\"Draws a polygon around the faces, then saves to output_filename.\n",
    "\n",
    "    Args:\n",
    "      image: a file containing the image with the faces.\n",
    "      faces: a list of faces found in the file. This should be in the format\n",
    "          returned by the Vision API.\n",
    "      output_filename: the name of the image file to be created, where the\n",
    "          faces have polygons drawn around them.\n",
    "    \"\"\"\n",
    "    im = Image.open(image)\n",
    "    draw = ImageDraw.Draw(im)\n",
    "\n",
    "    for face in faces:\n",
    "        box = [(vertex.x, vertex.y)\n",
    "               for vertex in face.bounding_poly.vertices]\n",
    "        draw.line(box + [box[0]], width=5, fill='#00ff00')\n",
    "\n",
    "    im.save(output_filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def look_for_faces(input_filename, output_filename, max_results):\n",
    "    with open(input_filename, 'rb') as image:\n",
    "        faces = detect_face(image, max_results)\n",
    "        print('Found {} face{}'.format(\n",
    "            len(faces), '' if len(faces) == 1 else 's'))\n",
    "\n",
    "        print('Writing to file {}'.format(output_filename))\n",
    "        # Reset the file pointer, so we can read the file again\n",
    "        image.seek(0)\n",
    "        highlight_faces(image, faces, output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Set some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_IMAGE=\"wisdom_of_the_crowd.jpg\"\n",
    "OUTPUT_IMAGE=\"DETECTED_WISDOM.jpg\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### INPUT\n",
    "![wisdom_of_the_crowd.jpg MISSING](wisdom_of_the_crowd.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "look_for_faces(INPUT_IMAGE, OUTPUT_IMAGE,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample of the output\n",
    "\n",
    "![facedetection.png](../images/facedetection.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: When you are ready, let's export this\n",
    " 1. Open terminal\n",
    " 2. Change into course, module7, labs folder\n",
    " 3. Convert to a script: `jupyter-nbconvert --to script FaceDetection.ipynb`\n",
    "```\n",
    "[NbConvertApp] Converting notebook StorageTestCode.ipynb to script\n",
    "[NbConvertApp] Writing 4740 bytes to StorageTestCode.py\n",
    "```\n",
    "\n",
    "#### Move the generated script using `scp` or copy and paste techniques to get it to your VM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: SUBMISSION\n",
    "* Add a screenshot like the one shown above in the `Sample of the output` for the lab submission\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Your Notebook!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
